{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 212: Data Science Programming 1\n",
    "___\n",
    "\n",
    "### Week 7: Data Cleaning and Preparation\n",
    "___\n",
    "\n",
    "### Mon., May 14, and Wed., May 16, 2018\n",
    "---\n",
    "\n",
    "**Question:**\n",
    "- What capabilities does Python provide to clean, transform, and re-arrange data? \n",
    "\n",
    "**Objectives:**\n",
    "- Filter out and fill in missing values\n",
    "- Remove duplicates\n",
    "- Transform data, replace values, and rename index\n",
    "- Discretize and bin data\n",
    "- Resample data \n",
    "- Compute indicators\n",
    "- Manipulate strings and use regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "PREVIOUS_MAX_ROWS = pd.options.display.max_rows\n",
    "pd.options.display.max_rows = 20\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "!cat examples/ex5.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Missing data occurs commonly in many data analysis applications.\n",
    "All of the descriptive statistics on pandas objects exclude missing data by default. For numeric data, pandas uses the floating-point value NaN (Not a Number) to represent missing data. We call this a sentinel value that can be easily detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "string_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado'])\n",
    "string_data\n",
    "string_data.isnull()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "string_data[0] = None\n",
    "string_data.isnull()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Out Missing Data\n",
    "In statistics applications, NA data may either be data that does not exist or that exists but was not observed\n",
    "(through problems with data collection, for example). When cleaning up data for\n",
    "analysis, it is often important to do analysis on the missing data itself to identify data\n",
    "collection problems or potential biases in the data caused by missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dropna()**  Filter axis labels based on whether values for each label have missing data. For Series, it returns non-null data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from numpy import nan as NA\n",
    "data = pd.Series([1, NA, 3.5, NA, 7])\n",
    "data.dropna()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data[data.notnull()]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dropna()** With DataFrame objects, things are a bit more complex. You may want to drop rows\n",
    "or columns that are all NA or only those containing any NAs. dropna by default drops\n",
    "any row containing a missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA],\n",
    "                     [NA, NA, NA], [NA, 6.5, 3.]])\n",
    "cleaned = data.dropna()\n",
    "data\n",
    "cleaned```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing how='all' will only drop rows that are all NA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.dropna(how='all')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data[4] = NA\n",
    "data\n",
    "data.dropna(axis=1, how='all')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related way to filter out DataFrame rows tends to concern time series data. Suppose\n",
    "you want to keep only rows containing a certain number of observations. You can\n",
    "indicate this with the thresh argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "df = pd.DataFrame(np.random.randn(7, 3))\n",
    "df.iloc[:4, 1] = NA\n",
    "df.iloc[:2, 2] = NA\n",
    "df\n",
    "df.dropna()\n",
    "df.dropna(thresh=2)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling In Missing Data\n",
    "Rather than filtering out missing data (and potentially discarding other data along\n",
    "with it), you may want to fill in the “holes” in any number of ways. For most purposes,\n",
    "the fillna method is the workhorse function to use. Calling fillna with a\n",
    "constant replaces missing values with that value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "df.fillna(0)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling fillna with a dict, you can use a different fill value for each column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "df.fillna({1: 0.5, 2: 0})```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fillna returns a new object, but you can modify the existing object in-place:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "_ = df.fillna(0, inplace=True)\n",
    "df```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same interpolation methods available for reindexing can be used with fillna:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "df = pd.DataFrame(np.random.randn(6, 3))\n",
    "df.iloc[2:, 1] = NA\n",
    "df.iloc[4:, 2] = NA\n",
    "df\n",
    "df.fillna(method='ffill')\n",
    "df.fillna(method='ffill', limit=2)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With fillna you can do lots of other things with a little creativity. For example, you\n",
    "might pass the mean or median value of a Series:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data = pd.Series([1., NA, 3.5, NA, 7])\n",
    "data.fillna(data.mean())```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise for cleaning missing data for the following data sets:\n",
    "A dataset of events that occured in American Football games:\n",
    "[Detailed NFL Play-by-Play Data 2009-2017](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016/data)\n",
    "\n",
    "A dataset of building permits issued in San Francisco:\n",
    "[San Francisco Building Permits](https://www.kaggle.com/aparnashastry/building-permit-applications-data/data)\n",
    "\n",
    "Here's what we're going to do:\n",
    "\n",
    "- Take a first look at the data\n",
    "- See how many missing data points we have\n",
    "- Figure out why the data is missing\n",
    "- Drop missing values\n",
    "- Filling in missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'],\n",
    "                     'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "data```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame method duplicated returns a boolean Series indicating whether each\n",
    "row is a duplicate (has been observed in a previous row) or not:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.duplicated()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatedly, drop_duplicates returns a DataFrame where the duplicated array is\n",
    "False:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.drop_duplicates()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatedly, drop_duplicates returns a DataFrame where the duplicated array is\n",
    "False:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data['v1'] = range(7)\n",
    "data.drop_duplicates(['k1'])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duplicated and drop_duplicates by default keep the first observed value combination.\n",
    "Passing keep='last' will return the last one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.drop_duplicates(['k1', 'k2'], keep='last')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data Using a Function or Mapping\n",
    "For many datasets, you may wish to perform some transformation based on the values\n",
    "in an array, Series, or column in a DataFrame. Consider the following hypothetical\n",
    "data collected about various kinds of meat:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',\n",
    "                              'Pastrami', 'corned beef', 'Bacon',\n",
    "                              'pastrami', 'honey ham', 'nova lox'],\n",
    "                     'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to add a column indicating the type of animal that each food\n",
    "came from. Let’s write down a mapping of each distinct meat type to the kind of\n",
    "animal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "meat_to_animal = {\n",
    "  'bacon': 'pig',\n",
    "  'pulled pork': 'pig',\n",
    "  'pastrami': 'cow',\n",
    "  'corned beef': 'cow',\n",
    "  'honey ham': 'pig',\n",
    "  'nova lox': 'salmon'\n",
    "}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map method on a Series accepts a function or dict-like object containing a mapping,\n",
    "but here we have a small problem in that some of the meats are capitalized and\n",
    "others are not. Thus, we need to convert each value to lowercase using the str.lower\n",
    "Series method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "lowercased = data['food'].str.lower()\n",
    "lowercased\n",
    "data['animal'] = lowercased.map(meat_to_animal)\n",
    "data```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also have passed a function that does all the work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data['food'].map(lambda x: meat_to_animal[x.lower()])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using map is a convenient way to perform element-wise transformations and other\n",
    "data cleaning–related operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Values\n",
    "Filling in missing data with the fillna method is a special case of more general value\n",
    "replacement. As you’ve already seen, map can be used to modify a subset of values in\n",
    "an object but replace provides a simpler and more flexible way to do so. Let’s consider\n",
    "this Series:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "data```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The -999 values might be sentinel values for missing data. To replace these with NA\n",
    "values that pandas understands, we can use replace, producing a new Series (unless\n",
    "you pass inplace=True):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.replace(-999, np.nan)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to replace multiple values at once, you instead pass a list and then the\n",
    "substitute value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.replace([-999, -1000], np.nan)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a different replacement for each value, pass a list of substitutes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.replace([-999, -1000], [np.nan, 0])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument passed can also be a dict:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.replace({-999: np.nan, -1000: 0})```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Axis Indexes\n",
    "Like values in a Series, axis labels can be similarly transformed by a function or mapping\n",
    "of some form to produce new, differently labeled objects. You can also modify\n",
    "the axes in-place without creating a new data structure. Here’s a simple example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                    index=['Ohio', 'Colorado', 'New York'],\n",
    "                    columns=['one', 'two', 'three', 'four'])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like a Series, the axis indexes have a map method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "transform = lambda x: x[:4].upper()\n",
    "data.index.map(transform)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can assign to index, modifying the DataFrame in-place:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.index = data.index.map(transform)\n",
    "data```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create a transformed version of a dataset without modifying the original,\n",
    "a useful method is rename:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.rename(index=str.title, columns=str.upper)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, rename can be used in conjunction with a dict-like object providing new values\n",
    "for a subset of the axis labels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.rename(index={'OHIO': 'INDIANA'},\n",
    "            columns={'three': 'peekaboo'})```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename saves you from the chore of copying the DataFrame manually and assigning\n",
    "to its index and columns attributes. Should you wish to modify a dataset in-place,\n",
    "pass inplace=True:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data.rename(index={'OHIO': 'INDIANA'}, inplace=True)\n",
    "data```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization and Binning\n",
    "Continuous data is often discretized or otherwise separated into “bins” for analysis.\n",
    "Suppose you have data about a group of people in a study, and you want to group\n",
    "them into discrete age buckets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s divide these into bins of 18 to 25, 26 to 35, 36 to 60, and finally 61 and older. To\n",
    "do so, you have to use cut, a function in pandas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "cats = pd.cut(ages, bins)\n",
    "cats```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object pandas returns is a special Categorical object. The output you see\n",
    "describes the bins computed by pandas.cut. You can treat it like an array of strings\n",
    "indicating the bin name; internally it contains a categories array specifying the distinct\n",
    "category names along with a labeling for the ages data in the codes attribute:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cats.codes\n",
    "cats.categories\n",
    "pd.value_counts(cats)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pd.value_counts(cats) are the bin counts for the result of pandas.cut.\n",
    "\n",
    "Consistent with mathematical notation for intervals, a parenthesis means that the side\n",
    "is open, while the square bracket means it is closed (inclusive). You can change which\n",
    "side is closed by passing right=False:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pd.cut(ages, [18, 26, 36, 61, 100], right=False)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass your own bin names by passing a list or array to the labels option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "group_names = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']\n",
    "pd.cut(ages, bins, labels=group_names)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass an integer number of bins to cut instead of explicit bin edges, it will compute\n",
    "equal-length bins based on the minimum and maximum values in the data.\n",
    "Consider the case of some uniformly distributed data chopped into fourths:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data = np.random.rand(20)\n",
    "pd.cut(data, 4, precision=2)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision=2 option limits the decimal precision to two digits.\n",
    "\n",
    "A closely related function, qcut, bins the data based on sample quantiles. Depending\n",
    "on the distribution of the data, using cut will not usually result in each bin having the\n",
    "same number of data points. Since qcut uses sample quantiles instead, by definition\n",
    "you will obtain roughly equal-size bins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data = np.random.randn(1000)  # Normally distributed\n",
    "cats = pd.qcut(data, 4)  # Cut into quartiles\n",
    "cats\n",
    "pd.value_counts(cats)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to cut you can pass your own quantiles (numbers between 0 and 1, inclusive):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Manipulation\n",
    "Python has long been a popular raw data manipulation language in part due to its\n",
    "ease of use for string and text processing. Most text operations are made simple with\n",
    "the string object’s built-in methods. For more complex pattern matching and text\n",
    "manipulations, regular expressions may be needed. pandas adds to the mix by enabling\n",
    "you to apply string and regular expressions concisely on whole arrays of data,\n",
    "additionally handling the annoyance of missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Object Methods\n",
    "In many string munging and scripting applications, built-in string methods are sufficient.\n",
    "As an example, a comma-separated string can be broken into pieces with\n",
    "split:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "val = 'a,b,  guido'\n",
    "val.split(',')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split is often combined with strip to trim whitespace (including line breaks):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pieces = [x.strip() for x in val.split(',')]\n",
    "pieces```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These substrings could be concatenated together with a two-colon delimiter using\n",
    "addition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "first, second, third = pieces\n",
    "first + '::' + second + '::' + third```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this isn’t a practical generic method. A faster and more Pythonic way is to pass a\n",
    "list or tuple to the join method on the string '::':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "'::'.join(pieces)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other methods are concerned with locating substrings. Using Python’s in keyword is\n",
    "the best way to detect a substring, though index and find can also be used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "'guido' in val\n",
    "val.index(',')\n",
    "val.find(':')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference between find and index is that index raises an exception if the\n",
    "string isn’t found (versus returning –1):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "val.index(':')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatedly, count returns the number of occurrences of a particular substring:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "val.count(',')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace will substitute occurrences of one pattern for another. It is commonly used\n",
    "to delete patterns, too, by passing an empty string:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "val.replace(',', '::')\n",
    "val.replace(',', '')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions\n",
    "Regular expressions provide a flexible way to search or match (often more complex)\n",
    "string patterns in text. A single expression, commonly called a regex, is a string\n",
    "formed according to the regular expression language. Python’s built-in re module is\n",
    "responsible for applying regular expressions to strings.\n",
    "\n",
    "The re module functions fall into three categories: pattern matching, substitution,\n",
    "and splitting. Naturally these are all related; a regex describes a pattern to locate in the\n",
    "text, which can then be used for many purposes. \n",
    "\n",
    "Suppose we wanted to split a string with a variable number of whitespace characters\n",
    "(tabs, spaces, and newlines). The regex describing one or more whitespace characters\n",
    "is \\s+:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import re\n",
    "text = \"foo    bar\\t baz  \\tqux\"\n",
    "re.split('\\s+', text)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call re.split('\\s+', text), the regular expression is first compiled, and\n",
    "then its split method is called on the passed text. You can compile the regex yourself\n",
    "with re.compile, forming a reusable regex object:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "regex = re.compile('\\s+')\n",
    "regex.split(text)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, instead, you wanted to get a list of all patterns matching the regex, you can use the\n",
    "findall method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "regex.findall(text)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match and search are closely related to findall. While findall returns all matches\n",
    "in a string, search returns only the first match. More rigidly, match only matches at\n",
    "the beginning of the string. As a less trivial example, let’s consider a block of text and\n",
    "a regular expression capable of identifying most email addresses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "text = \"\"\"Dave dave@google.com\n",
    "Steve steve@gmail.com\n",
    "Rob rob@gmail.com\n",
    "Ryan ryan@yahoo.com\n",
    "\"\"\"\n",
    "pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}'\n",
    "\n",
    "# re.IGNORECASE makes the regex case-insensitive\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using findall on the text produces a list of the email addresses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "regex.findall(text)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search returns a special match object for the first email address in the text. For the\n",
    "preceding regex, the match object can only tell us the start and end position of the\n",
    "pattern in the string:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "m = regex.search(text)\n",
    "m\n",
    "text[m.start():m.end()]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regex.match returns None, as it only will match if the pattern occurs at the start of the\n",
    "string:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print(regex.match(text))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatedly, sub will return a new string with occurrences of the pattern replaced by the\n",
    "a new string:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print(regex.sub('REDACTED', text))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to find email addresses and simultaneously segment each\n",
    "address into its three components: username, domain name, and domain suffix. To\n",
    "do this, put parentheses around the parts of the pattern to segment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})'\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A match object produced by this modified regex returns a tuple of the pattern components\n",
    "with its groups method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "m = regex.match('wesm@bright.net')\n",
    "m.groups()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findall returns a list of tuples when the pattern has groups:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "regex.findall(text)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub also has access to groups in each match using special symbols like \\1 and \\2. The\n",
    "symbol \\1 corresponds to the first matched group, \\2 corresponds to the second, and\n",
    "so forth:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print(regex.sub(r'Username: \\1, Domain: \\2, Suffix: \\3', text))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise \n",
    "If a row in a DataFrame belongs to multiple categories, things are a bit more complicated.\n",
    "Let’s look at the MovieLens 1M dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mnames = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_table('datasets/movielens/movies.dat', sep='::',\n",
    ".....: header=None, names=mnames)\n",
    "movies[:10]\n",
    "```\n",
    "\n",
    "Adding indicator variables for each genre requires a little bit of wrangling. First, we\n",
    "extract the list of unique genres in the dataset:\n",
    "```\n",
    "all_genres = []\n",
    "for x in movies.genres:\n",
    ".....: all_genres.extend(x.split('|'))\n",
    "genres = pd.unique(all_genres)\n",
    "\n",
    "genres\n",
    "```\n",
    "\n",
    "One way to construct the indicator DataFrame is to start with a DataFrame of all\n",
    "zeros:\n",
    "```\n",
    "zero_matrix = np.zeros((len(movies), len(genres)))\n",
    "dummies = pd.DataFrame(zero_matrix, columns=genres)\n",
    "```\n",
    "Now, iterate through each movie and set entries in each row of dummies to 1. To do\n",
    "this, we use the dummies.columns to compute the column indices for each genre:\n",
    "```\n",
    "gen = movies.genres[0]\n",
    "gen.split('|')\n",
    "\n",
    "dummies.columns.get_indexer(gen.split('|'))\n",
    "```\n",
    "Then, we can use .iloc to set values based on these indices:\n",
    "```\n",
    "for i, gen in enumerate(movies.genres):\n",
    ".....: indices = dummies.columns.get_indexer(gen.split('|'))\n",
    ".....: dummies.iloc[i, indices] = 1\n",
    ".....:\n",
    "```\n",
    "Then, as before, you can combine this with movies:\n",
    "```\n",
    "movies_windic = movies.join(dummies.add_prefix('Genre_'))\n",
    "movies_windic.iloc[0]\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
